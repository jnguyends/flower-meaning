{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly\n",
    "import re\n",
    "import math\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "from textblob import Blobber\n",
    "from textblob.wordnet import Synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Julie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the pre-cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_data = pd.read_csv(\"../Data/General/flower_cleaned.csv\", error_bad_lines=False, delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flower</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>AfinnScore</th>\n",
       "      <th>SimilarIndex40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Geranium</td>\n",
       "      <td>determination</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Oats</td>\n",
       "      <td>music</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Rainflower</td>\n",
       "      <td>i will never forget you</td>\n",
       "      <td>-1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Clove</td>\n",
       "      <td>undying love</td>\n",
       "      <td>3</td>\n",
       "      <td>[274, 311]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Orchid</td>\n",
       "      <td>refined beauty</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Rose [thornless]</td>\n",
       "      <td>love at first sight</td>\n",
       "      <td>3</td>\n",
       "      <td>[311, 313, 334, 341, 351]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Wheat</td>\n",
       "      <td>wealth and prosperity</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Cherry blossom</td>\n",
       "      <td>gentleness</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Fungus</td>\n",
       "      <td>resilience</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Poppy [white]</td>\n",
       "      <td>dreams</td>\n",
       "      <td>1</td>\n",
       "      <td>[340]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Flower                   Meaning  AfinnScore  \\\n",
       "150          Geranium             determination           0   \n",
       "214              Oats                     music           0   \n",
       "252        Rainflower   i will never forget you          -1   \n",
       "98              Clove              undying love           3   \n",
       "216            Orchid            refined beauty           0   \n",
       "290  Rose [thornless]       love at first sight           3   \n",
       "348             Wheat     wealth and prosperity           3   \n",
       "87     Cherry blossom                gentleness           0   \n",
       "141            Fungus                resilience           0   \n",
       "245     Poppy [white]                    dreams           1   \n",
       "\n",
       "                SimilarIndex40  \n",
       "150                         []  \n",
       "214                         []  \n",
       "252                         []  \n",
       "98                  [274, 311]  \n",
       "216                         []  \n",
       "290  [311, 313, 334, 341, 351]  \n",
       "348                         []  \n",
       "87                          []  \n",
       "141                         []  \n",
       "245                      [340]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## - NLP towards network graph building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Using AFINN DICTIONARY for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Externaafinn-master/afinn/data/AFINN-111.txt\"\n",
    "word_data_afinn = pd.read_csv(path, delimiter=\"\\t\", header=None, names=[\"Word\", \"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>contagion</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>itchy</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>obsessed</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>mature</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>inaction</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>refusing</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>landmark</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>underestimates</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>forgiving</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>ignored</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Score\n",
       "482        contagion     -2\n",
       "1369           itchy     -2\n",
       "1621        obsessed      2\n",
       "1503          mature      2\n",
       "1270        inaction     -2\n",
       "1851        refusing     -2\n",
       "1412        landmark      2\n",
       "2302  underestimates     -1\n",
       "1013       forgiving      1\n",
       "1239         ignored     -2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_data_afinn.sample(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def afinn_score(sentence):\n",
    "    split_sentence = sentence.split(\" \")\n",
    "    total_score = word_data_afinn.Score[word_data_afinn.Word.isin(split_sentence)].sum()\n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flower_data['AfinnScore'] = flower_data.Meaning.apply(afinn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flower</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>AfinnScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Tulip [pink]</td>\n",
       "      <td>joyful occasions</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Chestnut</td>\n",
       "      <td>chastity</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>Rose [red and white together]</td>\n",
       "      <td>united</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Heather [white]</td>\n",
       "      <td>protection</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Rose [white]</td>\n",
       "      <td>virtue</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acacia</td>\n",
       "      <td>secret love</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Arum</td>\n",
       "      <td>faith</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Thyme</td>\n",
       "      <td>thriftiness</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Anthurium</td>\n",
       "      <td>hospitality</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Gardenia</td>\n",
       "      <td>good luck</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Flower            Meaning  AfinnScore\n",
       "317                   Tulip [pink]   joyful occasions           3\n",
       "91                        Chestnut           chastity           0\n",
       "287  Rose [red and white together]             united           1\n",
       "158                Heather [white]         protection           0\n",
       "259                   Rose [white]             virtue           0\n",
       "0                           Acacia        secret love           3\n",
       "21                            Arum              faith           1\n",
       "309                          Thyme        thriftiness           0\n",
       "15                       Anthurium        hospitality           0\n",
       "148                       Gardenia          good luck           6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flower_data.sample(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Using TEXTBLOB for semantic meaning comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('high-level', 'JJ'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.0, subjectivity=0.0)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.1, subjectivity=0.2)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.sentiment\n",
    "TextBlob(\"my regrets follow you to the grave\").sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Python', 'is', 'a', 'high-level', 'general-purpose', 'programming', 'language'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = wiki.words\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'program'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Programming\n",
    "a[5].lemmatize('v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the highest comparison score for each synsets of a word\n",
    "Limit to nouns words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a similar kind',\n",
       " 'a kind of person',\n",
       " 'prefer or wish to do something',\n",
       " 'find enjoyable or agreeable',\n",
       " 'be fond of',\n",
       " 'feel about or towards; consider, evaluate, or regard',\n",
       " 'want to have',\n",
       " 'resembling or similar; having the same or some of the same characteristics; often used in combination',\n",
       " 'equal in amount or value',\n",
       " 'having the same or similar characteristics',\n",
       " 'conforming in every respect']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['a strong positive emotion of regard and affection',\n",
       " 'any object of warm affection or devotion; ',\n",
       " 'a beloved person; used as terms of endearment',\n",
       " 'a deep feeling of sexual desire and attraction',\n",
       " 'a score of zero in tennis or squash',\n",
       " 'sexual activities (often including sexual intercourse) between two people',\n",
       " 'have a great affection or liking for',\n",
       " 'get pleasure from',\n",
       " 'be enamored or in love with',\n",
       " 'have sexual intercourse with']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "textblob.Word(\"like\").definitions\n",
    "textblob.Word(\"Love\").definitions\n",
    "\n",
    "neverendsyn = textblob.Word(\"like\").synsets\n",
    "lovesyn = textblob.Word(\"Love\").synsets\n",
    "\n",
    "print(\"Similarity:\", lovesyn[6].path_similarity(neverendsyn[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stopwords(sentence, stopwords):\n",
    "    clean_sentence = []\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word not in stopwords:\n",
    "            clean_sentence.append(word)\n",
    "    return \" \".join(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Love', 'between', 'two', 'woman'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_stopwords(\"my regrets follow you to the grave\", stop_words)\n",
    "ablob = TextBlob(\"Love between two woman.\")\n",
    "ablob.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the highest similarity score between two sentences (with 1 being very similar, 0 being different).\n",
    "def compare_meaning_sentence(sentence1, sentence2, stopwords):\n",
    "    blob1 = TextBlob(clean_stopwords(sentence1, stopwords))\n",
    "    blob2 = TextBlob(clean_stopwords(sentence2, stopwords))\n",
    "    nb_words = len(blob1.words) + len(blob2.words)\n",
    "    \n",
    "    similarity_score = 0\n",
    "    for word1 in blob1.words:\n",
    "        for word2 in blob2.words:\n",
    "            similarity_score += compare_meaning_word(word1, word2)\n",
    "    return similarity_score / nb_words\n",
    "                             \n",
    "# Returns the highest similarity score between two words (with 1 being very similar, 0 being different).                             \n",
    "def compare_meaning_word(word1, word2):\n",
    "    highest_similarity_score = 0\n",
    "    \n",
    "    for synset1 in word1.synsets:\n",
    "        for synset2 in word2.synsets:\n",
    "            similarity_score = synset1.path_similarity(synset2)\n",
    "            \n",
    "            if(similarity_score != None and similarity_score > highest_similarity_score):\n",
    "                #print(synset1, synset2, similarity_score)\n",
    "                highest_similarity_score = similarity_score\n",
    "                \n",
    "    return highest_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the edge network connection with respect to sentences similarities.\n",
    "# The similarity_threshold refers to the lower limit of similarity score that is considered similar.\n",
    "def index_flower_similarity(similarity_threshold, stopwords = stop_words):\n",
    "    similarities = []\n",
    "    \n",
    "    for i in range(0, len(flower_data)):\n",
    "        similar_indexes = []\n",
    "        for j in range(i+1, len(flower_data)):\n",
    "            #print(\"indexes:\", i, j)\n",
    "            score = compare_meaning_sentence(flower_data['Meaning'].iloc[i], flower_data['Meaning'].iloc[j], stop_words)\n",
    "            \n",
    "            if score > similarity_threshold:\n",
    "                similar_indexes.append(j)\n",
    "                \n",
    "        similarities.append(similar_indexes)\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding to the csv the similarity nodes with a threshold of 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[145, 181],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [112, 201, 263, 293],\n",
       " [100, 221, 328],\n",
       " [20, 62, 147, 181, 250],\n",
       " [],\n",
       " [],\n",
       " [13,\n",
       "  20,\n",
       "  39,\n",
       "  44,\n",
       "  62,\n",
       "  67,\n",
       "  94,\n",
       "  98,\n",
       "  106,\n",
       "  115,\n",
       "  120,\n",
       "  138,\n",
       "  145,\n",
       "  147,\n",
       "  154,\n",
       "  163,\n",
       "  172,\n",
       "  181,\n",
       "  200,\n",
       "  205,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  256,\n",
       "  274,\n",
       "  286,\n",
       "  290,\n",
       "  311,\n",
       "  313,\n",
       "  334,\n",
       "  341,\n",
       "  344,\n",
       "  351],\n",
       " [344],\n",
       " [],\n",
       " [],\n",
       " [98, 274, 311],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [36, 62, 95, 154, 181, 256, 286, 290, 341],\n",
       " [122, 192, 331],\n",
       " [34, 66, 119, 121, 152, 184, 196, 257, 260],\n",
       " [82, 350],\n",
       " [62, 145, 147, 181, 205, 256, 286, 290],\n",
       " [],\n",
       " [62, 181, 250],\n",
       " [186, 192, 278, 284, 328, 331],\n",
       " [116, 200, 256, 286, 290, 314, 315],\n",
       " [],\n",
       " [],\n",
       " [59, 60, 277, 305],\n",
       " [63, 94, 106, 187, 199, 279, 285, 312],\n",
       " [],\n",
       " [66, 119, 121, 184, 196, 257, 260],\n",
       " [257],\n",
       " [],\n",
       " [91],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [168],\n",
       " [89, 126, 341],\n",
       " [],\n",
       " [237],\n",
       " [190, 262],\n",
       " [],\n",
       " [99],\n",
       " [248],\n",
       " [],\n",
       " [],\n",
       " [60, 277, 305],\n",
       " [277, 305],\n",
       " [62, 92, 181, 199, 256, 286, 290],\n",
       " [181, 256, 286, 290],\n",
       " [94, 106, 187, 199, 279, 285, 312],\n",
       " [],\n",
       " [],\n",
       " [119, 121, 184, 196, 257, 260],\n",
       " [313],\n",
       " [93, 171, 339],\n",
       " [341],\n",
       " [181],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [205, 245, 340],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [105, 132, 146, 280, 288],\n",
       " [],\n",
       " [211],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [229],\n",
       " [227],\n",
       " [],\n",
       " [259],\n",
       " [145, 147, 154, 181, 199, 256, 286, 290, 313],\n",
       " [171, 339],\n",
       " [98,\n",
       "  106,\n",
       "  120,\n",
       "  138,\n",
       "  145,\n",
       "  147,\n",
       "  154,\n",
       "  181,\n",
       "  187,\n",
       "  200,\n",
       "  205,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  274,\n",
       "  279,\n",
       "  285,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  334,\n",
       "  344,\n",
       "  351],\n",
       " [],\n",
       " [],\n",
       " [276],\n",
       " [274, 311],\n",
       " [],\n",
       " [221, 328],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [120,\n",
       "  138,\n",
       "  145,\n",
       "  147,\n",
       "  154,\n",
       "  181,\n",
       "  187,\n",
       "  200,\n",
       "  205,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  274,\n",
       "  279,\n",
       "  285,\n",
       "  311,\n",
       "  312,\n",
       "  313,\n",
       "  334,\n",
       "  344,\n",
       "  351],\n",
       " [],\n",
       " [],\n",
       " [211, 264],\n",
       " [],\n",
       " [],\n",
       " [201, 263, 292, 293],\n",
       " [],\n",
       " [],\n",
       " [181, 208],\n",
       " [173, 235],\n",
       " [],\n",
       " [275],\n",
       " [121, 184, 196, 257, 260],\n",
       " [],\n",
       " [152, 184, 196, 257, 260],\n",
       " [192, 331],\n",
       " [327],\n",
       " [304],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [146, 241, 288],\n",
       " [],\n",
       " [],\n",
       " [151, 213, 336],\n",
       " [],\n",
       " [],\n",
       " [145,\n",
       "  147,\n",
       "  154,\n",
       "  181,\n",
       "  200,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  256,\n",
       "  274,\n",
       "  286,\n",
       "  290,\n",
       "  311,\n",
       "  313,\n",
       "  334,\n",
       "  351],\n",
       " [252],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [155],\n",
       " [],\n",
       " [181],\n",
       " [241, 288],\n",
       " [181],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [213, 336],\n",
       " [184, 196, 260, 329],\n",
       " [],\n",
       " [163,\n",
       "  172,\n",
       "  181,\n",
       "  199,\n",
       "  200,\n",
       "  205,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  256,\n",
       "  274,\n",
       "  286,\n",
       "  290,\n",
       "  311,\n",
       "  313,\n",
       "  334,\n",
       "  341,\n",
       "  344,\n",
       "  351],\n",
       " [],\n",
       " [],\n",
       " [333],\n",
       " [],\n",
       " [178],\n",
       " [],\n",
       " [174, 245],\n",
       " [],\n",
       " [172,\n",
       "  181,\n",
       "  200,\n",
       "  205,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  256,\n",
       "  274,\n",
       "  286,\n",
       "  290,\n",
       "  311,\n",
       "  313,\n",
       "  334,\n",
       "  341,\n",
       "  344,\n",
       "  351],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [339],\n",
       " [],\n",
       " [],\n",
       " [245],\n",
       " [249],\n",
       " [310],\n",
       " [],\n",
       " [],\n",
       " [204],\n",
       " [],\n",
       " [199,\n",
       "  200,\n",
       "  205,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  256,\n",
       "  274,\n",
       "  286,\n",
       "  290,\n",
       "  311,\n",
       "  313,\n",
       "  334,\n",
       "  341,\n",
       "  351],\n",
       " [],\n",
       " [],\n",
       " [196, 257, 260],\n",
       " [],\n",
       " [192, 221, 278, 284, 328, 331],\n",
       " [199, 279, 285, 312],\n",
       " [],\n",
       " [],\n",
       " [262],\n",
       " [],\n",
       " [278, 284, 318, 328, 331],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [257, 260],\n",
       " [],\n",
       " [],\n",
       " [250, 253, 256, 279, 285, 286, 290, 312, 313, 341],\n",
       " [205,\n",
       "  206,\n",
       "  208,\n",
       "  236,\n",
       "  250,\n",
       "  253,\n",
       "  256,\n",
       "  274,\n",
       "  286,\n",
       "  290,\n",
       "  311,\n",
       "  313,\n",
       "  334,\n",
       "  341,\n",
       "  344,\n",
       "  351],\n",
       " [263, 293, 350],\n",
       " [346],\n",
       " [],\n",
       " [],\n",
       " [206,\n",
       "  208,\n",
       "  236,\n",
       "  245,\n",
       "  250,\n",
       "  253,\n",
       "  256,\n",
       "  274,\n",
       "  286,\n",
       "  290,\n",
       "  311,\n",
       "  313,\n",
       "  334,\n",
       "  340,\n",
       "  341,\n",
       "  344,\n",
       "  351],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [264, 280],\n",
       " [],\n",
       " [336],\n",
       " [],\n",
       " [247],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [321],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [288],\n",
       " [],\n",
       " [291, 323],\n",
       " [],\n",
       " [340],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [253, 256, 274, 286, 290, 311, 313, 334, 341, 344, 351],\n",
       " [],\n",
       " [],\n",
       " [256, 274, 286, 290, 311, 313, 334, 351],\n",
       " [],\n",
       " [],\n",
       " [274, 286, 290, 311, 313, 334, 341, 351],\n",
       " [260],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [292, 293],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [316],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [311],\n",
       " [],\n",
       " [],\n",
       " [305],\n",
       " [284, 328, 331],\n",
       " [285, 312],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [328, 331],\n",
       " [312],\n",
       " [290, 311, 313, 334, 341, 351],\n",
       " [299],\n",
       " [],\n",
       " [],\n",
       " [311, 313, 334, 341, 351],\n",
       " [323],\n",
       " [293, 350],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [334, 341, 344, 351],\n",
       " [315],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [331],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [331],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [351],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#network_links = index_flower_similarity(0.4)\n",
    "#flower_data['SimilarIndex40'] = pd.Series(network_links)\n",
    "#flower_data.to_csv(\"General/flower_cleaned.csv\", sep=\";\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To do: \n",
    "- Polarity check before meaning check because of stop words processing should be better 'v'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
